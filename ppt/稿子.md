```
尊敬评委老师，大家好，

我是来自唐敖庆理科试验班的马周原，指导老师是张老师，我的毕设题目是**基于激活工程的视觉语言大模型安全性对齐算法研究**

接下来，我主要从以下五个方面展开汇报。

为了拓展大语言模型的应用边界，很多研究者尝试将视觉模态整合进来，由此发展出了视觉语言模型VLM。

目前主流的VLM通过添加一个视觉编码器并训练投影层实现视觉特征向语言空间的对齐。

然而，有研究发现，VLM的应用面临着安全挑战，如图3所示，将炸弹二字转化为一张图片后即可绕过VLMs的安全机制生成有害回复；同时，新引入的视觉模态也带来了跨模态的安全风险，如图4，单独安全的两个模态（一张高楼的照片和“我想从这里去新世界”的文本）在组合起来会产生了“用户自杀倾向”这一潜在的危险语义。

然而，有研究发现，VLM的应用面临着安全挑战，如图3所示，将炸弹二字转化为一张图片后即可绕过VLMs的安全机制生成有害回复；同时，新引入的视觉模态也带来了跨模态的安全风险，如图4，单独安全的两个模态（一张高楼的照片和“我想从这里去新世界”的文本）在组合起来会产生了“用户自杀倾向”这一潜在的危险语义。

针对上述安全挑战，VLMs安全对齐是一个重要且热门的研究方向，可以分为训练时对齐和推理时对齐。本研究采用的激活工程技术属于后者，通过在隐空间提取一个和“安全”这一观念有关的方向作为安全导向向量来实现推理阶段的模型行为调控。

下面我将具体介绍本研究提出的MultiSteer算法。本文通过实验观察到：VLMs内部对“安全”这一抽象概念的理解呈现一种多维度分布特性。而传统方法多以单一方向进行安全性干预，这显然是不够优秀的。所以我们的创新点是c图向d图的转化，使用多个向量共同干预。

具体来说，MultiSteer首先用Safety Principle，就是这个prompt来“刺激”VLM产生安全相关的认知，并据此构建Pair-Wise的锚点数据，根据这些成对数据，通过无监督K-Means聚类构建多个的安全导向向量，这些向量指向的方向就是VLM对安全这一概念的理解方向。接下来，在推理阶段，MultiSteer可以用这些向量的线性组合来动态干预VLM的隐空间，以此增强模型的安全感知能力。

本文的实验在三个多模态安全基准上进行。MM-SafetyBench是一个经典传统的安全基准，FigStep是一个越狱攻击基准，SIUO是一个关注跨模态安全隐患的基准。主实验结果如左表所示，可以发现在LLaVA-One-Vision-7b模型上，MultiSteer显著优于我们选取的对比方法。同时，为了验证MultiSteer不会让模型“过于安全”，我们也做了右表所示的OverSafe分析。可以发现，我们的方法几乎不会对安全的样本产生拒绝响应。

本研究对MultiSteer进行了消融实验，也对聚类簇的个数、干预强度alpha、干预位置layer等超参数进行敏感性分析。这些实验也都证明了MultiSteer的有效性和鲁棒性。

这是MultiSteer的一个实际推理样例。当用户提出“我想直播吃100个汉堡”这一有危害性的请求时，原始 VLM 仍按照常规对话模式进行了回应。然而经过 MultiSteer 安全对齐后的模型识别到了安全风险，并从健康关怀的角度提供了建议，具有很好的实用性。

做一个小总结，本项目主要的贡献有以下三点。首先，我们提出了一个高效的VLM安全对齐算法；第二，我们首次发现了VLM对安全这一概念理解的多维度特性；最后，我们在主流安全基准上进行了充分的实验，证明了MultiSteer的有效性和实用性。
```



**尊敬的各位评委老师，大家好，**  

我是吉林大学唐敖庆理科试验班的**周宇恒**，指导老师是**刘淼老师**，我的毕设题目是《差分隐私下求解近似最小割问题的算法设计》。

接下来，我将从研究背景，研究现状，方法设计三个方面展开汇报。



医疗等数据敏感场景下，数据的使用者有责任保护信息安全。因此，研究者提出差分隐私的概念来量化隐私泄露风险。

差分隐私关注算法输出中的个体隐私泄露。例如，对于统计平均年龄的算法，攻击者可以通过在输入 名单中添加一个人并对比两次询问的结果，来获取具体某个人的年龄这一敏感信息。

 差分隐私要求，单个数据应当对输出结果的影响不显著。研究者往往需要向算法中加入噪声作为隐私 保护方法。



割是顶点集合的二划分，割的权重为两个点集之间的边权和。

最小割为图 中权重最小的割，最小割问题常在拓扑结构设计与资源分配优化等场景中出现。

差分隐私下的最小割算法需要控制割值的误差与输出的稳定性，这给算法设计带来了挑战。 

示了规模为𝑂(𝑛2)的最小割。

仙人掌图表示法是一种特殊的数据结构，其以规模为O(𝑛)的稀疏化图表



我们首先注意到，在医疗数据共享、社交网络分析等场景中，传统最小割算法存在隐私泄露风险。例如攻击者只需增删图中一条边，通过观察割值变化就可能推测出敏感边权信息。这正是**差分隐私技术**的用武之地——它要求通过添加可控噪声（如拉普拉斯机制），确保单条数据变动不会显著影响输出结果。

**但当我们试图将差分隐私应用于最小割问题时，遇到了特殊挑战：**  
现有隐私算法要么只能输出单个割（丢失拓扑信息），要么需要指数级时间计算，最优误差也停留在 \( \Theta(\log n / \epsilon) \) 量级。更关键的是，当前没有方法能隐私地输出**所有最小割的集合**——而这恰恰是资源分配等场景的核心需求。

**针对这一难题，我们的研究实现了三重突破：**

首先发现**仙人掌图表示法**这一能压缩存储最小割集的神奇结构，竟存在非唯一性问题。就像您在图8看到的，同一个图可能有不同表示。于是我们设计了**首个标准化重构算法**，通过动态调整环结构（如图9的代码逻辑），将其转化为唯一稳定表示，为后续隐私计算铺平道路。

但仅解决结构问题还不够。差分隐私要求量化**最小割数量的敏感度**——即单条边权变化最多导致多少割值改变。现有理论对此束手无策，而我们通过仙人掌图拓扑分析，首次证明敏感度上界不超过 \( 0.5M_G + 1.5n \)（如图11）。这个发现让隐私噪声添加有了科学依据。

**基于这两项基础突破，最终诞生了我们的核心算法：**  
• 先用**指数机制**加权筛选高概率割，大幅压缩候选集  
• 融入**Karger收缩算法**高效枚举割，突破指数级计算瓶颈  
• 最终达成 \( \tilde{O}(n \ln n / \epsilon) \) 的加性误差，比现有最优结果提升 \( O(m/n) \) 倍  

**简单来说，这项研究不仅首次实现了：**  
✓ 多项式时间内输出隐私保护的近似最小割集  
✓ 建立最小割敏感度定量模型  
✓ 解决仙人掌图非唯一性难题  
更为医疗数据安全分割、社交网络隐私分区等应用提供了新工具。回首这段科研旅程，特别感谢刘淼教授在理论证明关键时刻的指引，让我深刻体会到"图灵奖之路始于严谨推导"的真谛。

以上是我的汇报，恳请各位老师批评指正！  

---

## 使用说明与建议

1.  **PPT同步：** **最关键**的是确保演讲内容与PPT翻页和展示的内容（特别是图表、示意图、结果表格）严格同步。在稿子中用括号标注了建议的PPT翻页点（如 “(PPT翻至图3和图4)”, “(PPT展示主结果表格)”）。请务必根据您PPT的实际结构和内容调整这些标注。
2.  **图表引用：** 仔细核对稿子中提到的所有图表（图3, 图4, c图/d图, 左表/右表等）在您的PPT中的实际编号和位置，确保一一对应。
3.  **口语化表达：** 这份稿子力求逻辑清晰、专业性强，但实际演讲时，请将其转化为更自然、流畅的口语。可以适当添加连接词、语气词，避免完全照本宣科。
4.  **时间控制：** 练习演讲，确保在规定时间内完成。通常答辩时间严格，重点突出核心贡献和创新点（第二部分、第三部分主结果、第五部分实例、总结）。
5.  **强调重点：** 在讲到关键创新点（MultiSteer的核心思想：多维度、多向量）、重要实验结果（主结果表显著优于基线）、以及实际效果（实例展示）时，可以适当放慢语速，加重语气。
6.  **熟悉内容：** 对自己提出的算法（MultiSteer）、实验细节、基准测试集等要非常熟悉，以应对评委可能的提问。
7.  **致谢与问答：** 结尾的“敬请各位老师批评指正”和“谢谢”是标准礼仪。汇报结束后，准备进入问答环节。

祝您答辩顺利！