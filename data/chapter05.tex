\chapter{差分隐私背景下近似最小割求解算法}

本章将详细阐述差分隐私背景下近似最小割求解算法的具体设计方案。
该算法不仅需满足差分隐私的要求，同时要有效控制近似最小割与真实最小割之间的加法误差；
此外，算法还需尽可能多地输出有效的近似最小割的解，并兼顾算法的运行效率。
形式化的来说，算法的输入为图$G$，给定隐私参数$\varepsilon,\delta$和误差$\Delta$，
算法应当能$(\varepsilon,\delta)$-差分隐私地输出一个尽可能大的割集$R$，使得对于任意割$r\in R$，
满足$w(r)\leq \Phi_G+\Delta$。

\section{基于差分隐私图的算法设计}

算法设计的难点在于，输入的数据需要隐私化处理后才能使用。
对图直接进行差分隐私是一种可行的方案，且在隐私化后的图上进行计算可以使用非差分隐私算法。
定理\ref{the:dpgraph}展示了Liu等人设计的差分隐私图算法。
回顾该算法内容，
对于一个输入$G$，算法可以以高概率$(\varepsilon,\delta)$-差分隐私地输出一个合成图$\hat G$。
对于合成图中任意不相交的点集$ S, T \subseteq V_G $，均满足如下关系
    \begin{equation}
        |w_G(S, T) - w_{\hat{G}}(S, T)| = O\left(\frac{\sqrt{nm}}{\varepsilon} \log^3 \left(\frac{n}{\delta}\right)\right)   
    \end{equation}
这表明，对于原图中的任意最小割$R$，其在合成图$\hat G$中的割值为$\Phi_G+ O\left(\frac{\sqrt{nm}}{\varepsilon} \log^3 \left(\frac{n}{\delta}\right)\right)$。
由此可见，合成图$\hat G$作为图$G$隐私处理后的结果，能够确保最小割有较好的近似，
也就是说，该方法能确保合成图中的近似最小割数量不少于原图的最小割数量。

在完成图的隐私化步骤后，算法可以枚举合成图中的所有割，并将割值与$\Phi_G+\Delta$比较。
因此，算法需要差分隐私地发布最小割割值$\Phi_G$，即得到一个误差较小的近似值$\hat \Phi_G$，
这一任务可以由拉普拉斯机制完成。

差分隐私地计算最小割值的方法如下：
首先，使用定理\ref{the:mincut}中的Karger最小割算法，
可以以高概率求出图$G$的最小割值$\Phi_G$。
在边相邻的两个图$G,G'$中，恰好存在一条边边权相差$1$，其它边边权均相等，
因此，图$G$中的一个最小割在图$G'$中的割值最多增加一。
根据定理\ref{laplace}中的拉普拉斯机制，
将最小割值作为函数$f$，则其对应的敏感度$\Delta=1$，
因此对最小割的真实加入噪声后，
算法能以$\varepsilon$-差分隐私的发布最小割值的近似值$\hat \Phi_G=\Phi_G+X$，
其中$X\sim Lap(1/\varepsilon)$。

使用拉普拉斯机制带来的误差为$O(\frac{1}{\varepsilon})$。
具体分析如下：拉普拉斯分布$Lap(1/\varepsilon)$的概率密度函数为
\begin{equation}
    f(x)=\frac \varepsilon{2} e^{-\varepsilon\|x\|}
\end{equation}
对$x$取绝对值后，函数变成指数分布的形式，其概率密度函数为
\begin{equation}
    f(x)=\varepsilon e^{-\varepsilon x},(x\geq 0)
\end{equation}
绝对值的累计分布函数为
\begin{equation}
    P(|X|\leq t)=1-e^{-\varepsilon x},(t\geq 0)
\end{equation}
由该式可得，有至少$1-\alpha$的概率使得
$|X|\leq \frac1\varepsilon\ln\left(\frac1\alpha\right)$。
因此，算法有高概率满足$\hat\Phi(G)=\Phi(G)+O(\frac1\varepsilon)$。

在差分隐私地求得最小割的近似值后，算法可以通过枚举割并对割值进行判断来求得解。
具体来说，算法将$\beta$定为一个足够大的常数，并枚举$V_G$的所有子集$X$，
判断$\Delta(X)$在合成图$\hat G$中的割值是否满足
$w_{\hat G}(X)\leq \hat \Phi_G+\beta \frac{\sqrt{nm}}{\varepsilon} \log^3 \left(\frac{n}{\delta}\right)$，
满足条件的$\Delta(X)$被视为近似最小割并加入输出的割集$R$中。
需要注意的是，输出的割集$R$会包含图$G$中的所有最小割和部分近似最小割，
因此割集$R$的大小可能超过$n^2$。

使用定理\ref{the:basic}这一基本组合定理，
可以为算法中差分隐私步骤的$\epsilon$和$\delta$赋合适的常系数，
不难说明，
上述算法是$(\varepsilon,\delta)$-差分隐私的，
且能以高概率输出至少$M_G$个
$O\left(\frac{\sqrt{nm}\log^3 \left(\frac{n}{\delta}\right)}{\varepsilon} \right)$近似的最小割。

\section{基于$k$优选择机制的算法设计}

除了对图直接进行隐私化处理外，算法也可以在对原图进行若干计算后再进行差分隐私。
定理\ref{the:topk}中提到的$k$优选择机制可以$(\varepsilon,\delta)$-差分隐私地
在$m$个值中取$k$个$O(\frac{\sqrt{k\log(m/\delta)}}{\varepsilon})$近似最小值。
因此，算法可以差分隐私的获取最小割值$\hat \Phi_G$和最小割的数量$\hat M_G$，
并用$k$优选择机制在所有$2^n$个割中选择权值前$\hat M_G$小的割。
通过该方法，算法可以获得$\hat M_G$个割，再进行筛选处理可以得到差分隐私背景下的近似最小割。

回顾最小割数量的敏感度，根据定理\ref{sen}，给定边相邻图$G,G'$，
其中$G'$由在$G$中加入一条边权为$1$的边得到，则有
$0\leq M_G-M_{G'}\leq \frac{M_G}2+1.5n$。
由于边相邻图的最小割数量较大，因此需要取对数处理。
不妨令$a=\log_2(M_G+3n)$，其敏感度为$1$。
接下来，使用拉普拉斯机制差分隐私的输出$a$的值$\hat a$，
并令差分隐私的最小割数量为$\hat M_G=min{\{max{\{0,2^{\hat a}-3n\}},n^2\}}$。

得到估计值$\hat\Phi_G$和$\hat M_G$后，
算法可以枚举$V_G$的所有子集$X$，
并计算割$\Delta(X)$在原图$G$中的割值。
对所有$2^n$个割值使用定理\ref{the:topk}中的$k$优选择机制，
算法可以得到$\hat M_G$个割
以及每个割的$O(\frac{n\sqrt{n\log(1/\delta)}}{\varepsilon})$近似值。
由于对最小割数量的估计存在误差，因此原图的第$\hat M_G$小割可能并非最小割，
因此，筛选处理在本节的算法仍然是必要的。
与上一节类似，
算法将$\beta$定为一个足够大的常数，
并枚举所有这$\hat M_G$个割，并分别判断其割值是否小于
$\hat \Phi_G+\beta \frac{n\sqrt{n\log(1/\delta)}}{\varepsilon}$，
满足条件的割视被视为近似最小割并加入输出的割集$R$中。

相比于基于差分隐私图的算法，该算法加入了对最小割数量的估计，
因此适用于要求输出割数量与原图$G$中最小割数量相仿时的场景。
然而，本文中给出的差分隐私的最小割数量估计算法误差较大，
算法可能出现输出割集大小远小于原图$G$中最小割数量的问题，这与目标相悖。

为了解决$\hat M_G$过小的情况，算法需要进行一些修改。
对于图$G$的$M_G$个最小割中的每个割，其在$k$优选择机制中的的割值为$\Phi_G+O(\frac{\sqrt{kn\log(1/\delta)}}{\varepsilon})$。
$\hat M_G$的规模为$O(n^2)$，因此代入$k$的取值后，
可以保证原图$G$的最小割在筛选步骤中不会被排除在外。
因此当$\hat M_G\leq M_G$时，$k$优选择机制得到的割一定不会在筛选步骤中被排除在外。
由于筛选机制的存在，可以令$k=n^2\geq M_G$，
这样能保证输出的近似最小割数量不少于原图最小割的数量。

修改后的基于$k$优选择机制的算法的表现并不比基于差分隐私图的算法更好，
但其提供了一种对原图进行进一步处理以实现算法优化的可能性。

\section{加法近似参数的优化}

当$m=\Theta (n^2)$时，
基于差分隐私图的算法与基于$k$优选择机制的算法，
其加法近似参数均为$\tilde O(\frac{n\sqrt n}{\varepsilon})$。
本节提出一种融合指数机制与Karger收缩算法的方法，旨在降低加法近似参数。

回顾$k$优选择机制，算法从$m$个数中选择了$k$个最小值，
其加法近似参数$O(\frac{\sqrt{k\log(m/\delta)}}{\varepsilon})$同时由$m,k$决定。
而受到最小割数量的限制，在最坏情况下，$k$的取值为$\Theta (n^2)$。
因此要想优化加法近似参数，需要从降低$m$入手。

在上一节中，算法枚举了点集的所有子集来寻找割，
这是因为在没有给定更多条件的情况下，
图中所有割都是潜在的$k$小割，因此$m=2^n$。
算法需要缩小潜在$k$小割的范围来使$m$值降低。

由于$k$的值为$O(n^2)$，因此$k$小割可以视为原图的一个近似最小割。
前文提到，当$\alpha$为一常数时，
Karger收缩算法可以在多项式复杂度内找到所有$\alpha$乘法近似最小割。
具体来说，根据定理\ref{the:agl}，一个给定的$\alpha$乘法近似最小割在收缩至$\lfloor2\alpha\rfloor$个顶点时，
其有效的概率为$\Omega(n^{-2\alpha})$。因此，执行$n^{2\alpha+1}$次Karger收缩算法，
则该$\alpha$乘法近似最小割以高概率在至少一次算法执行中有效。因此，以高概率所有$\alpha$乘法近似最小割都被找到。
Karger收缩算法本身为非差分隐私算法，
因此在处理其输入时需要考虑隐私性。


设调用$k$优选择机制时算法的加法近似参数为$\Delta'$，
则应有$\Delta'\leq \Delta$。
若如此，则对于图$G$的任意最小割，
在调用$k$优选择机制时割值均小于$\Phi_G+\Delta$，
则可保证找到的近似最小割数量不少于原图的最小割数量。

Karger收缩算法可以找到割值不超过$\alpha\Phi_G$的所有割，
而本文提出的算法需要寻找割值不超过$\Phi_G+\Delta'$的最小割。
前者采用乘法近似参数，后者采用加法近似参数，
参数形式的差异要求对算法进行额外分析。
联立两式得$\alpha=1+\frac {\Delta'}{\Phi_G}$，
由于Karger收缩算法求得的近似最小割数量与$\alpha$有关，
因此$\alpha$的值需取为常数。
也就是说，算法需要对$G$进行一定处理来保证$\frac {\Delta'}{\Phi_G}$存在一个常数上界。

对$G$的处理应该在引入较少误差$\Delta'$的同时，
又能提高最小割的割值。
具体方法为在图$G=(V,E)$中差分隐私地加边加边。
算法使用指数分布来差分隐私地选择加边的边集。
首先给定参数$T$，算法按如下方法构造一个边集$H$：
\begin{itemize}
    \item 将图$G$的$n$个顶点按任意顺序排列成一个环。
    \item 对环上任意相邻两点，在$H$中加入$T/2$条连接这两个点的边权为$1$的边。
\end{itemize}
接下来，令$H_0\subset H_1,\ldots,\subset H_{|H|}$为任意大小严格递增的边集序列，且$H_{|H|}=H$。
对于每个下标$i\in[1,|H|]$，令其权值为$t_i=|\Phi_{(V,E\cup H_i)}-T|$。
使用指数机制选择下标$i$，则有高概率得到一个解，满足
\begin{equation}
    Pr[|\Phi_{(V,E\cup H_i)}-T|>t_{min}+\frac{2\ln (nT)}{\varepsilon}+\frac{2t}{\varepsilon}]\leq e^{-t}
\end{equation}
容易证明，$t_{min}=\max\{0,\Phi_G-T\}$。
令$T=\frac{20\ln n}{\varepsilon}$，令$t=2\ln n$。
整理，记
\begin{equation}
    t_{range}=\frac{2\ln (nT)}{\varepsilon}+\frac{2t}{\varepsilon}=\frac{6\ln n+2\ln T}{\varepsilon}= \frac{6\ln n+2\ln(20\ln n)-2\ln \varepsilon}{\varepsilon}
\end{equation}
当$\varepsilon\in[\frac1n,\frac12]$,$n\geq 200$时，有$t_{range}\leq \frac{10\ln n}{\varepsilon}$。

记$\hat G=(V,E\cup H_i)$，讨论$\Phi_G$与$T$的关系并化简，可以得出算法以$1-\frac1{n^2}$的概率满足
\begin{equation}
    10\ln n/\varepsilon<\Phi_{\hat G}<\Phi_G+30\ln n/\varepsilon
\end{equation}

在上述生成$\hat G$的过程中，加入边的数量为$O(\frac{n\ln n}{\varepsilon})$，
且有$1\leq \frac{\Phi_G}{\Phi_{\hat G}}\leq 4$，且边集的选取满足差分隐私。
因此，只需要在$\hat G$中运行$n^9$次Karger收缩算法，就能以高概率找到$G$的所有近似最小割。
根据定理\ref{the:approximatemincutnumber}，$\alpha$乘法近似最小割的数量至多为$n^{2\alpha}$，
所以找到割的数量是$O(n^8)$的。
即$m=O(n^8)$，得到$k$优选择机制的加法近似参数为$O(\frac{n\sqrt{\log(n^8/\delta)}}{\varepsilon})$。
算法的总加法近似参数因为加边操作而限制为$O(\frac{n\ln n}{\varepsilon})$。

与上一节类似地，由于本文对最小割数量的估计方法误差较大，
本节的算法也需要采取一定修改。
算法定$k$的值为$n^2$，并按如上步骤找到权值$k$小的割。
接下来，差分隐私的发布最小割的值$\hat \Phi_G$，然后将$\beta$定为一个足够大的常数，
并对这$n^2$个割分别判断其割值是否小于
$\hat \Phi_G+\beta \frac{n\ln n}{\varepsilon}$，
满足条件的割被视为近似最小割并加入输出的割集$R$中。
\begin{theorem}
    给定$\varepsilon\in[\frac 1n,\frac12]$和$\delta$作为隐私参数。
    对于给定任意$n\geq 200$的图$G$，存在一个$(\epsilon,\delta)$-差分隐私算法，
    能够至少输出$M_G$个与最小割的割值$O(\frac{n\ln n}{\varepsilon})$近似的割。
\end{theorem}